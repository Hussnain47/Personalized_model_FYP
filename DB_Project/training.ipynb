{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>Sleeps</th>\n",
       "      <th>NoSleeps</th>\n",
       "      <th>isSleep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.649444e+12</td>\n",
       "      <td>1.649446e+12</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.649446e+12</td>\n",
       "      <td>1.649448e+12</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.649448e+12</td>\n",
       "      <td>1.649450e+12</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.649450e+12</td>\n",
       "      <td>1.649452e+12</td>\n",
       "      <td>59.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.649452e+12</td>\n",
       "      <td>1.649453e+12</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      StartTime       EndTime     1     2     3     4     5     6     7     8  \\\n",
       "0  1.649444e+12  1.649446e+12  86.0  86.0  87.0  87.0  87.0  87.0  88.0  88.0   \n",
       "1  1.649446e+12  1.649448e+12  82.0  82.0  82.0  82.0  81.0  81.0  81.0  81.0   \n",
       "2  1.649448e+12  1.649450e+12  75.0  75.0  74.0  74.0  74.0  74.0  73.0  73.0   \n",
       "3  1.649450e+12  1.649452e+12  59.0  60.0  60.0  60.0  60.0  60.0  61.0  61.0   \n",
       "4  1.649452e+12  1.649453e+12  66.0  66.0  65.0  65.0  65.0  64.0  64.0  64.0   \n",
       "\n",
       "   ...    24    25    26    27    28    29    30  Sleeps  NoSleeps  isSleep  \n",
       "0  ...  84.0  84.0  84.0  83.0  83.0  83.0  83.0       5        25    False  \n",
       "1  ...  77.0  76.0  76.0  76.0  76.0  75.0  75.0      29         1     True  \n",
       "2  ...  61.0  58.0  58.0  58.0  59.0  59.0  59.0      29         1     True  \n",
       "3  ...  64.0  65.0  65.0  65.0  65.0  66.0  66.0      30         0     True  \n",
       "4  ...  64.0  64.0  64.0  65.0  65.0  65.0  65.0      30         0     True  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"windowedData.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>isSleep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.649444e+12</td>\n",
       "      <td>1.649446e+12</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.649446e+12</td>\n",
       "      <td>1.649448e+12</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.649448e+12</td>\n",
       "      <td>1.649450e+12</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.649450e+12</td>\n",
       "      <td>1.649452e+12</td>\n",
       "      <td>59.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.649452e+12</td>\n",
       "      <td>1.649453e+12</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      StartTime       EndTime     1     2     3     4     5     6     7     8  \\\n",
       "0  1.649444e+12  1.649446e+12  86.0  86.0  87.0  87.0  87.0  87.0  88.0  88.0   \n",
       "1  1.649446e+12  1.649448e+12  82.0  82.0  82.0  82.0  81.0  81.0  81.0  81.0   \n",
       "2  1.649448e+12  1.649450e+12  75.0  75.0  74.0  74.0  74.0  74.0  73.0  73.0   \n",
       "3  1.649450e+12  1.649452e+12  59.0  60.0  60.0  60.0  60.0  60.0  61.0  61.0   \n",
       "4  1.649452e+12  1.649453e+12  66.0  66.0  65.0  65.0  65.0  64.0  64.0  64.0   \n",
       "\n",
       "   ...    22    23    24    25    26    27    28    29    30  isSleep  \n",
       "0  ...  85.0  84.0  84.0  84.0  84.0  83.0  83.0  83.0  83.0    False  \n",
       "1  ...  77.0  77.0  77.0  76.0  76.0  76.0  76.0  75.0  75.0     True  \n",
       "2  ...  67.0  64.0  61.0  58.0  58.0  58.0  59.0  59.0  59.0     True  \n",
       "3  ...  64.0  64.0  64.0  65.0  65.0  65.0  65.0  66.0  66.0     True  \n",
       "4  ...  64.0  64.0  64.0  64.0  64.0  65.0  65.0  65.0  65.0     True  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(data.columns[-3:-1], inplace=True, axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.columns[-1]] = data[data.columns[-1]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "361    1\n",
       "362    1\n",
       "363    1\n",
       "364    1\n",
       "365    1\n",
       "Name: isSleep, Length: 366, dtype: int32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data[data.columns[:-1]]\n",
    "result = data.iloc[:,-1]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, result, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LinearRegression()\n",
    "model2 = LogisticRegression()\n",
    "model3 = SVC()\n",
    "model4 = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self._y = np.empty(y.shape, dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train)\n",
    "model2.fit(X_train, y_train)\n",
    "model3.fit(X_train, y_train)\n",
    "model4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:291: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indices = (scores > 0).astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "pred1 = model1.predict(X_test)\n",
    "pred2 = model2.predict(X_test)\n",
    "pred3 = model3.predict(X_test)\n",
    "pred4 = model4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1490d059bc8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Linear Regression Validation Test # Designed by me XD\n",
    "plt.scatter(y_test, pred3, 10, alpha = 0.3, label = \"prediction\") # changing alpha and size for visualization from dif aspects\n",
    "plt.plot(y_test, y_test, 'red', label = \"Accuracy line\")\n",
    "plt.plot(y_test, np.ones_like(y_test)*max(y_test), 'green')\n",
    "plt.plot(y_test, np.ones_like(y_test)*min(y_test), 'green', label = \"Limit\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n",
      "Mean Absolute Error: 0.2895917212697016\n",
      "Mean Squared Error: 0.11510083579870796\n",
      "Root Mean Squared Error: 0.33926514085403464\n",
      "Model 2\n",
      "Mean Absolute Error: 0.33783783783783783\n",
      "Mean Squared Error: 0.33783783783783783\n",
      "Root Mean Squared Error: 0.5812381937190964\n",
      "Model 3\n",
      "Mean Absolute Error: 0.33783783783783783\n",
      "Mean Squared Error: 0.33783783783783783\n",
      "Root Mean Squared Error: 0.5812381937190964\n",
      "Model 4\n",
      "Mean Absolute Error: 0.06756756756756757\n",
      "Mean Squared Error: 0.06756756756756757\n",
      "Root Mean Squared Error: 0.25993762245501817\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 1\")\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, pred1))\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, pred1))\n",
    "print(\"Root Mean Squared Error:\", np.sqrt(mean_squared_error(y_test, pred1)))\n",
    "print(\"Model 2\")\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, pred2))\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, pred2))\n",
    "print(\"Root Mean Squared Error:\", np.sqrt(mean_squared_error(y_test, pred2)))\n",
    "print(\"Model 3\")\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, pred3))\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, pred3))\n",
    "print(\"Root Mean Squared Error:\", np.sqrt(mean_squared_error(y_test, pred3)))\n",
    "print(\"Model 4\")\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, pred4))\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, pred4))\n",
    "print(\"Root Mean Squared Error:\", np.sqrt(mean_squared_error(y_test, pred4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.80        49\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.66        74\n",
      "   macro avg       0.33      0.50      0.40        74\n",
      "weighted avg       0.44      0.66      0.53        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.80        49\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.66        74\n",
      "   macro avg       0.33      0.50      0.40        74\n",
      "weighted avg       0.44      0.66      0.53        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        49\n",
      "           1       0.83      1.00      0.91        25\n",
      "\n",
      "    accuracy                           0.93        74\n",
      "   macro avg       0.92      0.95      0.93        74\n",
      "weighted avg       0.94      0.93      0.93        74\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Installed Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Installed Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Installed Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Installed Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Installed Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred2))\n",
    "print(classification_report(y_test, pred3))\n",
    "print(classification_report(y_test, pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49  0]\n",
      " [25  0]]\n",
      "[[49  0]\n",
      " [25  0]]\n",
      "[[44  5]\n",
      " [ 0 25]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred2))\n",
    "print(confusion_matrix(y_test, pred3))\n",
    "print(confusion_matrix(y_test, pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "[CV 1/10] END ....................n_neighbors=1;, score=0.933 total time=   0.0s\n",
      "[CV 2/10] END ....................n_neighbors=1;, score=1.000 total time=   0.0s\n",
      "[CV 3/10] END ....................n_neighbors=1;, score=1.000 total time=   0.0s\n",
      "[CV 4/10] END ....................n_neighbors=1;, score=0.931 total time=   0.0s\n",
      "[CV 5/10] END ....................n_neighbors=1;, score=0.966 total time=   0.0s\n",
      "[CV 6/10] END ....................n_neighbors=1;, score=1.000 total time=   0.0s\n",
      "[CV 7/10] END ....................n_neighbors=1;, score=0.931 total time=   0.0s\n",
      "[CV 8/10] END ....................n_neighbors=1;, score=1.000 total time=   0.0s\n",
      "[CV 9/10] END ....................n_neighbors=1;, score=1.000 total time=   0.0s\n",
      "[CV 10/10] END ...................n_neighbors=1;, score=0.966 total time=   0.0s\n",
      "[CV 1/10] END ....................n_neighbors=2;, score=0.967 total time=   0.0s\n",
      "[CV 2/10] END ....................n_neighbors=2;, score=1.000 total time=   0.0s\n",
      "[CV 3/10] END ....................n_neighbors=2;, score=1.000 total time=   0.0s\n",
      "[CV 4/10] END ....................n_neighbors=2;, score=0.966 total time=   0.0s\n",
      "[CV 5/10] END ....................n_neighbors=2;, score=0.897 total time=   0.0s\n",
      "[CV 6/10] END ....................n_neighbors=2;, score=0.966 total time=   0.0s\n",
      "[CV 7/10] END ....................n_neighbors=2;, score=0.931 total time=   0.0s\n",
      "[CV 8/10] END ....................n_neighbors=2;, score=0.966 total time=   0.0s\n",
      "[CV 9/10] END ....................n_neighbors=2;, score=1.000 total time=   0.0s\n",
      "[CV 10/10] END ...................n_neighbors=2;, score=1.000 total time=   0.0s\n",
      "[CV 1/10] END ....................n_neighbors=3;, score=0.967 total time=   0.0s\n",
      "[CV 2/10] END ....................n_neighbors=3;, score=1.000 total time=   0.0s\n",
      "[CV 3/10] END ....................n_neighbors=3;, score=0.966 total time=   0.0s\n",
      "[CV 4/10] END ....................n_neighbors=3;, score=0.966 total time=   0.0s\n",
      "[CV 5/10] END ....................n_neighbors=3;, score=0.931 total time=   0.0s\n",
      "[CV 6/10] END ....................n_neighbors=3;, score=1.000 total time=   0.0s\n",
      "[CV 7/10] END ....................n_neighbors=3;, score=0.931 total time=   0.0s\n",
      "[CV 8/10] END ....................n_neighbors=3;, score=1.000 total time=   0.0s\n",
      "[CV 9/10] END ....................n_neighbors=3;, score=0.966 total time=   0.0s\n",
      "[CV 10/10] END ...................n_neighbors=3;, score=0.931 total time=   0.0s\n",
      "[CV 1/10] END ....................n_neighbors=4;, score=0.967 total time=   0.0s\n",
      "[CV 2/10] END ....................n_neighbors=4;, score=1.000 total time=   0.0s\n",
      "[CV 3/10] END ....................n_neighbors=4;, score=0.966 total time=   0.0s\n",
      "[CV 4/10] END ....................n_neighbors=4;, score=0.966 total time=   0.0s\n",
      "[CV 5/10] END ....................n_neighbors=4;, score=0.931 total time=   0.0s\n",
      "[CV 6/10] END ....................n_neighbors=4;, score=0.966 total time=   0.0s\n",
      "[CV 7/10] END ....................n_neighbors=4;, score=0.931 total time=   0.0s\n",
      "[CV 8/10] END ....................n_neighbors=4;, score=0.931 total time=   0.0s\n",
      "[CV 9/10] END ....................n_neighbors=4;, score=1.000 total time=   0.0s\n",
      "[CV 10/10] END ...................n_neighbors=4;, score=1.000 total time=   0.0s\n",
      "[CV 1/10] END ....................n_neighbors=5;, score=1.000 total time=   0.0s\n",
      "[CV 2/10] END ....................n_neighbors=5;, score=1.000 total time=   0.0s\n",
      "[CV 3/10] END ....................n_neighbors=5;, score=0.966 total time=   0.0s\n",
      "[CV 4/10] END ....................n_neighbors=5;, score=1.000 total time=   0.0s\n",
      "[CV 5/10] END ....................n_neighbors=5;, score=0.897 total time=   0.0s\n",
      "[CV 6/10] END ....................n_neighbors=5;, score=0.966 total time=   0.0s\n",
      "[CV 7/10] END ....................n_neighbors=5;, score=0.931 total time=   0.0s\n",
      "[CV 8/10] END ....................n_neighbors=5;, score=0.966 total time=   0.0s\n",
      "[CV 9/10] END ....................n_neighbors=5;, score=1.000 total time=   0.0s\n",
      "[CV 10/10] END ...................n_neighbors=5;, score=0.931 total time=   0.0s\n",
      "[CV 1/10] END ....................n_neighbors=6;, score=0.967 total time=   0.0s\n",
      "[CV 2/10] END ....................n_neighbors=6;, score=1.000 total time=   0.0s\n",
      "[CV 3/10] END ....................n_neighbors=6;, score=0.966 total time=   0.0s\n",
      "[CV 4/10] END ....................n_neighbors=6;, score=0.966 total time=   0.0s\n",
      "[CV 5/10] END ....................n_neighbors=6;, score=0.931 total time=   0.0s\n",
      "[CV 6/10] END ....................n_neighbors=6;, score=0.966 total time=   0.0s\n",
      "[CV 7/10] END ....................n_neighbors=6;, score=0.931 total time=   0.0s\n",
      "[CV 8/10] END ....................n_neighbors=6;, score=0.931 total time=   0.0s\n",
      "[CV 9/10] END ....................n_neighbors=6;, score=1.000 total time=   0.0s\n",
      "[CV 10/10] END ...................n_neighbors=6;, score=1.000 total time=   0.0s\n",
      "[CV 1/10] END ....................n_neighbors=7;, score=0.933 total time=   0.0s\n",
      "[CV 2/10] END ....................n_neighbors=7;, score=1.000 total time=   0.0s\n",
      "[CV 3/10] END ....................n_neighbors=7;, score=0.897 total time=   0.0s\n",
      "[CV 4/10] END ....................n_neighbors=7;, score=0.966 total time=   0.0s\n",
      "[CV 5/10] END ....................n_neighbors=7;, score=0.897 total time=   0.0s\n",
      "[CV 6/10] END ....................n_neighbors=7;, score=0.966 total time=   0.0s\n",
      "[CV 7/10] END ....................n_neighbors=7;, score=0.966 total time=   0.0s\n",
      "[CV 8/10] END ....................n_neighbors=7;, score=0.931 total time=   0.0s\n",
      "[CV 9/10] END ....................n_neighbors=7;, score=0.931 total time=   0.0s\n",
      "[CV 10/10] END ...................n_neighbors=7;, score=1.000 total time=   0.0s\n",
      "[CV 1/10] END ....................n_neighbors=8;, score=0.933 total time=   0.0s\n",
      "[CV 2/10] END ....................n_neighbors=8;, score=1.000 total time=   0.0s\n",
      "[CV 3/10] END ....................n_neighbors=8;, score=0.966 total time=   0.0s\n",
      "[CV 4/10] END ....................n_neighbors=8;, score=0.966 total time=   0.0s\n",
      "[CV 5/10] END ....................n_neighbors=8;, score=0.931 total time=   0.0s\n",
      "[CV 6/10] END ....................n_neighbors=8;, score=0.966 total time=   0.0s\n",
      "[CV 7/10] END ....................n_neighbors=8;, score=0.931 total time=   0.0s\n",
      "[CV 8/10] END ....................n_neighbors=8;, score=0.966 total time=   0.0s\n",
      "[CV 9/10] END ....................n_neighbors=8;, score=1.000 total time=   0.0s\n",
      "[CV 10/10] END ...................n_neighbors=8;, score=1.000 total time=   0.0s\n",
      "[CV 1/10] END ....................n_neighbors=9;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ....................n_neighbors=9;, score=1.000 total time=   0.0s\n",
      "[CV 3/10] END ....................n_neighbors=9;, score=0.966 total time=   0.0s\n",
      "[CV 4/10] END ....................n_neighbors=9;, score=1.000 total time=   0.0s\n",
      "[CV 5/10] END ....................n_neighbors=9;, score=0.931 total time=   0.0s\n",
      "[CV 6/10] END ....................n_neighbors=9;, score=0.966 total time=   0.0s\n",
      "[CV 7/10] END ....................n_neighbors=9;, score=0.966 total time=   0.0s\n",
      "[CV 8/10] END ....................n_neighbors=9;, score=0.966 total time=   0.0s\n",
      "[CV 9/10] END ....................n_neighbors=9;, score=0.966 total time=   0.0s\n",
      "[CV 10/10] END ...................n_neighbors=9;, score=0.931 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=10;, score=0.933 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=10;, score=1.000 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=10;, score=0.931 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=10;, score=0.966 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=10;, score=0.931 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=10;, score=0.966 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=10;, score=0.966 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=10;, score=0.966 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=10;, score=0.966 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=10;, score=1.000 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=11;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=11;, score=1.000 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=11;, score=0.966 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=11;, score=1.000 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=11;, score=0.897 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=11;, score=0.966 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=11;, score=0.966 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=11;, score=0.966 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=11;, score=0.931 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=11;, score=1.000 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=12;, score=0.933 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=12;, score=0.900 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=12;, score=0.897 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=12;, score=0.931 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=12;, score=0.931 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=12;, score=0.966 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=12;, score=0.966 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=12;, score=0.931 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=12;, score=0.931 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=12;, score=0.966 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=13;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=13;, score=0.900 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=13;, score=0.897 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=13;, score=0.931 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=13;, score=0.862 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=13;, score=0.966 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=13;, score=0.966 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=13;, score=0.966 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=13;, score=0.897 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=13;, score=0.966 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=14;, score=0.933 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=14;, score=0.900 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=14;, score=0.897 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=14;, score=0.931 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=14;, score=0.862 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=14;, score=0.966 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=14;, score=0.966 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=14;, score=0.897 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=14;, score=0.931 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=14;, score=0.966 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=15;, score=0.933 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=15;, score=0.900 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=15;, score=0.897 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=15;, score=0.966 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=15;, score=0.828 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=15;, score=0.966 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=15;, score=0.966 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=15;, score=0.897 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=15;, score=0.897 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=15;, score=1.000 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=16;, score=0.933 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=16;, score=0.900 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=16;, score=0.897 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=16;, score=0.897 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=16;, score=0.862 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=16;, score=0.931 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=16;, score=0.931 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=16;, score=0.862 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=16;, score=0.931 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=16;, score=0.966 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=17;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=17;, score=0.900 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=17;, score=0.897 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=17;, score=0.966 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=17;, score=0.828 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=17;, score=0.966 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=17;, score=0.931 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=17;, score=0.931 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=17;, score=0.897 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=17;, score=0.966 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=18;, score=0.933 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=18;, score=0.900 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=18;, score=0.862 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=18;, score=0.897 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=18;, score=0.828 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=18;, score=0.931 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=18;, score=0.931 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=18;, score=0.862 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=18;, score=0.897 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=18;, score=0.966 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=19;, score=0.933 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=19;, score=0.900 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=19;, score=0.828 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=19;, score=0.966 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=19;, score=0.793 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=19;, score=0.966 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=19;, score=0.931 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=19;, score=0.897 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=19;, score=0.897 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=19;, score=0.966 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=20;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=20;, score=0.900 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=20;, score=0.862 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=20;, score=0.897 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=20;, score=0.828 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=20;, score=0.897 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=20;, score=0.828 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=20;, score=0.862 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=20;, score=0.897 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=20;, score=0.931 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=21;, score=0.867 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=21;, score=0.900 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=21;, score=0.828 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=21;, score=0.862 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=21;, score=0.793 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=21;, score=0.897 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=21;, score=0.793 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=21;, score=0.862 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=21;, score=0.862 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=21;, score=0.931 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=22;, score=0.833 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=22;, score=0.900 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=22;, score=0.759 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=22;, score=0.828 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=22;, score=0.759 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=22;, score=0.897 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=22;, score=0.828 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=22;, score=0.759 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=22;, score=0.897 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=22;, score=0.897 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=23;, score=0.767 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=23;, score=0.900 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=23;, score=0.759 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=23;, score=0.862 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=23;, score=0.759 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=23;, score=0.897 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=23;, score=0.828 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=23;, score=0.759 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=23;, score=0.828 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=23;, score=0.931 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=24;, score=0.833 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=24;, score=0.900 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=24;, score=0.759 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=24;, score=0.862 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=24;, score=0.759 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=24;, score=0.793 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=24;, score=0.793 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=24;, score=0.759 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=24;, score=0.897 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=24;, score=0.862 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=25;, score=0.833 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=25;, score=0.900 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=25;, score=0.759 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=25;, score=0.828 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=25;, score=0.759 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=25;, score=0.793 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=25;, score=0.793 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=25;, score=0.759 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=25;, score=0.897 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=25;, score=0.862 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=26;, score=0.833 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=26;, score=0.900 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=26;, score=0.759 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=26;, score=0.724 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=26;, score=0.759 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=26;, score=0.793 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=26;, score=0.724 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=26;, score=0.759 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=26;, score=0.793 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=26;, score=0.793 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=27;, score=0.833 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=27;, score=0.900 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=27;, score=0.759 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=27;, score=0.724 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=27;, score=0.759 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=27;, score=0.793 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=27;, score=0.724 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=27;, score=0.759 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=27;, score=0.793 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=27;, score=0.793 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=28;, score=0.767 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=28;, score=0.800 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=28;, score=0.759 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=28;, score=0.690 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=28;, score=0.724 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=28;, score=0.759 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=28;, score=0.759 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=28;, score=0.759 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=28;, score=0.759 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=28;, score=0.759 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=29;, score=0.767 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=29;, score=0.800 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=29;, score=0.759 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=29;, score=0.690 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=29;, score=0.724 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=29;, score=0.759 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=29;, score=0.724 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=29;, score=0.759 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=29;, score=0.759 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=29;, score=0.759 total time=   0.0s\n",
      "[CV 1/10] END ...................n_neighbors=30;, score=0.767 total time=   0.0s\n",
      "[CV 2/10] END ...................n_neighbors=30;, score=0.700 total time=   0.0s\n",
      "[CV 3/10] END ...................n_neighbors=30;, score=0.759 total time=   0.0s\n",
      "[CV 4/10] END ...................n_neighbors=30;, score=0.724 total time=   0.0s\n",
      "[CV 5/10] END ...................n_neighbors=30;, score=0.724 total time=   0.0s\n",
      "[CV 6/10] END ...................n_neighbors=30;, score=0.759 total time=   0.0s\n",
      "[CV 7/10] END ...................n_neighbors=30;, score=0.759 total time=   0.0s\n",
      "[CV 8/10] END ...................n_neighbors=30;, score=0.724 total time=   0.0s\n",
      "[CV 9/10] END ...................n_neighbors=30;, score=0.759 total time=   0.0s\n",
      "[CV 10/10] END ..................n_neighbors=30;, score=0.759 total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "k_range = list(range(1, 31))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "grid = GridSearchCV(model4, param_grid, cv=10, scoring='accuracy', refit = True, return_train_score=False,verbose=3)\n",
    "grid_search=grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95        49\n",
      "           1       0.86      0.96      0.91        25\n",
      "\n",
      "    accuracy                           0.93        74\n",
      "   macro avg       0.92      0.94      0.93        74\n",
      "weighted avg       0.94      0.93      0.93        74\n",
      "\n",
      "\n",
      "[[45  4]\n",
      " [ 1 24]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))\n",
    "print()\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.695 total time=   0.0s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.695 total time=   0.0s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.690 total time=   0.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.690 total time=   0.0s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.707 total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf','linear']} \n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5ee9ef5a62fc822ad9330e3bcedfd41f1b11384e680eb6b06312cad0ce38c97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
